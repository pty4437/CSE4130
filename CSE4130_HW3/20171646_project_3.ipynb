{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.2, No BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 7s 16ms/step - loss: 1.1964 - accuracy: 0.6194 - val_loss: 0.7336 - val_accuracy: 0.7558\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7406 - accuracy: 0.7520 - val_loss: 0.6155 - val_accuracy: 0.7909\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6476 - accuracy: 0.7793 - val_loss: 0.5576 - val_accuracy: 0.8116\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5926 - accuracy: 0.7969 - val_loss: 0.5255 - val_accuracy: 0.8216\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5588 - accuracy: 0.8096 - val_loss: 0.5021 - val_accuracy: 0.8297\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5347 - accuracy: 0.8160 - val_loss: 0.4841 - val_accuracy: 0.8358\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5134 - accuracy: 0.8234 - val_loss: 0.4705 - val_accuracy: 0.8392\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4967 - accuracy: 0.8299 - val_loss: 0.4583 - val_accuracy: 0.8436\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.4863 - accuracy: 0.8313 - val_loss: 0.4557 - val_accuracy: 0.8409\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4728 - accuracy: 0.8353 - val_loss: 0.4435 - val_accuracy: 0.8467\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4652 - accuracy: 0.8387 - val_loss: 0.4387 - val_accuracy: 0.8476\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4571 - accuracy: 0.8416 - val_loss: 0.4285 - val_accuracy: 0.8503\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4450 - accuracy: 0.8445 - val_loss: 0.4262 - val_accuracy: 0.8508\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4399 - accuracy: 0.8474 - val_loss: 0.4171 - val_accuracy: 0.8553\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.4329 - accuracy: 0.8498 - val_loss: 0.4088 - val_accuracy: 0.8576\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.4258 - accuracy: 0.8499 - val_loss: 0.4091 - val_accuracy: 0.8582\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4202 - accuracy: 0.8533 - val_loss: 0.4020 - val_accuracy: 0.8595\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4153 - accuracy: 0.8535 - val_loss: 0.3994 - val_accuracy: 0.8622\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4109 - accuracy: 0.8562 - val_loss: 0.3921 - val_accuracy: 0.8627\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.4043 - accuracy: 0.8577 - val_loss: 0.3897 - val_accuracy: 0.8638\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3971 - accuracy: 0.8614 - val_loss: 0.3866 - val_accuracy: 0.8643\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.3956 - accuracy: 0.8608 - val_loss: 0.3874 - val_accuracy: 0.8635\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3908 - accuracy: 0.8615 - val_loss: 0.3814 - val_accuracy: 0.8653\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3880 - accuracy: 0.8626 - val_loss: 0.3765 - val_accuracy: 0.8689\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3829 - accuracy: 0.8657 - val_loss: 0.3739 - val_accuracy: 0.8687\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3781 - accuracy: 0.8659 - val_loss: 0.3706 - val_accuracy: 0.8702\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3759 - accuracy: 0.8676 - val_loss: 0.3696 - val_accuracy: 0.8696\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3716 - accuracy: 0.8669 - val_loss: 0.3676 - val_accuracy: 0.8703\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3688 - accuracy: 0.8680 - val_loss: 0.3642 - val_accuracy: 0.8720\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3658 - accuracy: 0.8702 - val_loss: 0.3626 - val_accuracy: 0.8718\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3619 - accuracy: 0.8715 - val_loss: 0.3605 - val_accuracy: 0.8719\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3592 - accuracy: 0.8719 - val_loss: 0.3593 - val_accuracy: 0.8733\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3562 - accuracy: 0.8731 - val_loss: 0.3571 - val_accuracy: 0.8733\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3545 - accuracy: 0.8739 - val_loss: 0.3564 - val_accuracy: 0.8729\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3499 - accuracy: 0.8755 - val_loss: 0.3547 - val_accuracy: 0.8737\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3496 - accuracy: 0.8750 - val_loss: 0.3501 - val_accuracy: 0.8771\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3455 - accuracy: 0.8767 - val_loss: 0.3499 - val_accuracy: 0.8762\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3446 - accuracy: 0.8756 - val_loss: 0.3472 - val_accuracy: 0.8762\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3422 - accuracy: 0.8778 - val_loss: 0.3476 - val_accuracy: 0.8773\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3412 - accuracy: 0.8773 - val_loss: 0.3453 - val_accuracy: 0.8781\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3377 - accuracy: 0.8792 - val_loss: 0.3479 - val_accuracy: 0.8773\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3339 - accuracy: 0.8808 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3322 - accuracy: 0.8814 - val_loss: 0.3418 - val_accuracy: 0.8786\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3306 - accuracy: 0.8817 - val_loss: 0.3398 - val_accuracy: 0.8790\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3274 - accuracy: 0.8830 - val_loss: 0.3425 - val_accuracy: 0.8787\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3273 - accuracy: 0.8823 - val_loss: 0.3362 - val_accuracy: 0.8804\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3241 - accuracy: 0.8835 - val_loss: 0.3370 - val_accuracy: 0.8806\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3221 - accuracy: 0.8854 - val_loss: 0.3364 - val_accuracy: 0.8792\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3198 - accuracy: 0.8857 - val_loss: 0.3335 - val_accuracy: 0.8813\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3179 - accuracy: 0.8857 - val_loss: 0.3365 - val_accuracy: 0.8811\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3163 - accuracy: 0.8877 - val_loss: 0.3304 - val_accuracy: 0.8833\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3124 - accuracy: 0.8881 - val_loss: 0.3295 - val_accuracy: 0.8830\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3126 - accuracy: 0.8878 - val_loss: 0.3332 - val_accuracy: 0.8818\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3124 - accuracy: 0.8871 - val_loss: 0.3275 - val_accuracy: 0.8832\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3077 - accuracy: 0.8889 - val_loss: 0.3284 - val_accuracy: 0.8827\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3070 - accuracy: 0.8902 - val_loss: 0.3268 - val_accuracy: 0.8839\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3066 - accuracy: 0.8913 - val_loss: 0.3243 - val_accuracy: 0.8844\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3031 - accuracy: 0.8911 - val_loss: 0.3236 - val_accuracy: 0.8848\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3019 - accuracy: 0.8924 - val_loss: 0.3236 - val_accuracy: 0.8855\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3002 - accuracy: 0.8929 - val_loss: 0.3224 - val_accuracy: 0.8857\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8761\n",
      "0.8761000037193298\n",
      "Accuracy: 87.61%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.5, No BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 14ms/step - loss: 1.4219 - accuracy: 0.5107 - val_loss: 0.8140 - val_accuracy: 0.7207\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.9017 - accuracy: 0.6831 - val_loss: 0.6748 - val_accuracy: 0.7586\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.7783 - accuracy: 0.7286 - val_loss: 0.6099 - val_accuracy: 0.7836\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.7092 - accuracy: 0.7524 - val_loss: 0.5697 - val_accuracy: 0.7999\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6586 - accuracy: 0.7706 - val_loss: 0.5366 - val_accuracy: 0.8120\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6228 - accuracy: 0.7841 - val_loss: 0.5160 - val_accuracy: 0.8202\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5973 - accuracy: 0.7930 - val_loss: 0.4993 - val_accuracy: 0.8239\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5742 - accuracy: 0.7990 - val_loss: 0.4849 - val_accuracy: 0.8300\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5572 - accuracy: 0.8056 - val_loss: 0.4751 - val_accuracy: 0.8288\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5411 - accuracy: 0.8110 - val_loss: 0.4651 - val_accuracy: 0.8343\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.5314 - accuracy: 0.8147 - val_loss: 0.4545 - val_accuracy: 0.8390\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5197 - accuracy: 0.8180 - val_loss: 0.4466 - val_accuracy: 0.8396\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5031 - accuracy: 0.8226 - val_loss: 0.4396 - val_accuracy: 0.8428\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4985 - accuracy: 0.8246 - val_loss: 0.4330 - val_accuracy: 0.8447\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4922 - accuracy: 0.8255 - val_loss: 0.4257 - val_accuracy: 0.8465\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4847 - accuracy: 0.8300 - val_loss: 0.4243 - val_accuracy: 0.8492\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4744 - accuracy: 0.8324 - val_loss: 0.4170 - val_accuracy: 0.8510\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4711 - accuracy: 0.8336 - val_loss: 0.4137 - val_accuracy: 0.8527\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4658 - accuracy: 0.8352 - val_loss: 0.4091 - val_accuracy: 0.8537\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4589 - accuracy: 0.8383 - val_loss: 0.4061 - val_accuracy: 0.8548\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4501 - accuracy: 0.8403 - val_loss: 0.4035 - val_accuracy: 0.8543\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4486 - accuracy: 0.8414 - val_loss: 0.3995 - val_accuracy: 0.8570\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4442 - accuracy: 0.8429 - val_loss: 0.3960 - val_accuracy: 0.8589\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4400 - accuracy: 0.8445 - val_loss: 0.3916 - val_accuracy: 0.8594\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4360 - accuracy: 0.8448 - val_loss: 0.3890 - val_accuracy: 0.8611\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4300 - accuracy: 0.8468 - val_loss: 0.3865 - val_accuracy: 0.8608\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4296 - accuracy: 0.8470 - val_loss: 0.3844 - val_accuracy: 0.8619\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4217 - accuracy: 0.8504 - val_loss: 0.3817 - val_accuracy: 0.8633\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4208 - accuracy: 0.8495 - val_loss: 0.3782 - val_accuracy: 0.8648\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4167 - accuracy: 0.8531 - val_loss: 0.3777 - val_accuracy: 0.8635\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4154 - accuracy: 0.8518 - val_loss: 0.3758 - val_accuracy: 0.8643\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4104 - accuracy: 0.8545 - val_loss: 0.3737 - val_accuracy: 0.8651\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4060 - accuracy: 0.8562 - val_loss: 0.3709 - val_accuracy: 0.8658\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4048 - accuracy: 0.8568 - val_loss: 0.3700 - val_accuracy: 0.8666\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4025 - accuracy: 0.8567 - val_loss: 0.3681 - val_accuracy: 0.8683\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3979 - accuracy: 0.8591 - val_loss: 0.3648 - val_accuracy: 0.8692\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3969 - accuracy: 0.8581 - val_loss: 0.3648 - val_accuracy: 0.8687\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3960 - accuracy: 0.8597 - val_loss: 0.3615 - val_accuracy: 0.8694\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3932 - accuracy: 0.8596 - val_loss: 0.3605 - val_accuracy: 0.8704\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3898 - accuracy: 0.8592 - val_loss: 0.3580 - val_accuracy: 0.8708\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3870 - accuracy: 0.8620 - val_loss: 0.3588 - val_accuracy: 0.8700\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3847 - accuracy: 0.8635 - val_loss: 0.3555 - val_accuracy: 0.8721\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3822 - accuracy: 0.8633 - val_loss: 0.3543 - val_accuracy: 0.8717\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3817 - accuracy: 0.8635 - val_loss: 0.3531 - val_accuracy: 0.8735\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3789 - accuracy: 0.8649 - val_loss: 0.3520 - val_accuracy: 0.8752\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3758 - accuracy: 0.8660 - val_loss: 0.3495 - val_accuracy: 0.8748\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3728 - accuracy: 0.8665 - val_loss: 0.3506 - val_accuracy: 0.8729\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3721 - accuracy: 0.8664 - val_loss: 0.3484 - val_accuracy: 0.8749\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3713 - accuracy: 0.8666 - val_loss: 0.3459 - val_accuracy: 0.8763\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3690 - accuracy: 0.8680 - val_loss: 0.3480 - val_accuracy: 0.8747\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3666 - accuracy: 0.8686 - val_loss: 0.3431 - val_accuracy: 0.8777\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3669 - accuracy: 0.8692 - val_loss: 0.3437 - val_accuracy: 0.8766\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3617 - accuracy: 0.8704 - val_loss: 0.3445 - val_accuracy: 0.8754\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3616 - accuracy: 0.8696 - val_loss: 0.3412 - val_accuracy: 0.8763\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3603 - accuracy: 0.8712 - val_loss: 0.3410 - val_accuracy: 0.8760\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3566 - accuracy: 0.8717 - val_loss: 0.3391 - val_accuracy: 0.8776\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3591 - accuracy: 0.8706 - val_loss: 0.3380 - val_accuracy: 0.8781\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3547 - accuracy: 0.8730 - val_loss: 0.3368 - val_accuracy: 0.8798\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3510 - accuracy: 0.8735 - val_loss: 0.3359 - val_accuracy: 0.8787\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3516 - accuracy: 0.8745 - val_loss: 0.3347 - val_accuracy: 0.8805\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3614 - accuracy: 0.8698\n",
      "0.8697999715805054\n",
      "Accuracy: 86.98%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.8, No BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 14ms/step - loss: 1.9859 - accuracy: 0.2964 - val_loss: 1.2486 - val_accuracy: 0.6500\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 1.3898 - accuracy: 0.4927 - val_loss: 0.9015 - val_accuracy: 0.6891\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 1.1610 - accuracy: 0.5699 - val_loss: 0.7837 - val_accuracy: 0.7177\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 1.0343 - accuracy: 0.6176 - val_loss: 0.7243 - val_accuracy: 0.7370\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.9531 - accuracy: 0.6453 - val_loss: 0.6813 - val_accuracy: 0.7552\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.8955 - accuracy: 0.6671 - val_loss: 0.6515 - val_accuracy: 0.7626\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.8533 - accuracy: 0.6866 - val_loss: 0.6255 - val_accuracy: 0.7742\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.8172 - accuracy: 0.6995 - val_loss: 0.6074 - val_accuracy: 0.7805\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.7925 - accuracy: 0.7094 - val_loss: 0.5903 - val_accuracy: 0.7908\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.7605 - accuracy: 0.7201 - val_loss: 0.5744 - val_accuracy: 0.7925\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.7475 - accuracy: 0.7293 - val_loss: 0.5600 - val_accuracy: 0.8018\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7279 - accuracy: 0.7380 - val_loss: 0.5477 - val_accuracy: 0.8061\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.7097 - accuracy: 0.7460 - val_loss: 0.5348 - val_accuracy: 0.8128\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6942 - accuracy: 0.7499 - val_loss: 0.5296 - val_accuracy: 0.8155\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6851 - accuracy: 0.7544 - val_loss: 0.5185 - val_accuracy: 0.8216\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6777 - accuracy: 0.7581 - val_loss: 0.5157 - val_accuracy: 0.8217\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6569 - accuracy: 0.7665 - val_loss: 0.5038 - val_accuracy: 0.8236\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.6530 - accuracy: 0.7692 - val_loss: 0.4976 - val_accuracy: 0.8277\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6394 - accuracy: 0.7705 - val_loss: 0.4916 - val_accuracy: 0.8300\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.6310 - accuracy: 0.7764 - val_loss: 0.4867 - val_accuracy: 0.8312\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6202 - accuracy: 0.7800 - val_loss: 0.4804 - val_accuracy: 0.8303\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6152 - accuracy: 0.7830 - val_loss: 0.4767 - val_accuracy: 0.8336\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6107 - accuracy: 0.7848 - val_loss: 0.4716 - val_accuracy: 0.8357\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6065 - accuracy: 0.7873 - val_loss: 0.4684 - val_accuracy: 0.8358\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5976 - accuracy: 0.7930 - val_loss: 0.4630 - val_accuracy: 0.8365\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5945 - accuracy: 0.7896 - val_loss: 0.4591 - val_accuracy: 0.8379\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5876 - accuracy: 0.7937 - val_loss: 0.4564 - val_accuracy: 0.8378\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5793 - accuracy: 0.7968 - val_loss: 0.4551 - val_accuracy: 0.8407\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5792 - accuracy: 0.7977 - val_loss: 0.4509 - val_accuracy: 0.8418\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5721 - accuracy: 0.7993 - val_loss: 0.4470 - val_accuracy: 0.8413\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5694 - accuracy: 0.8005 - val_loss: 0.4427 - val_accuracy: 0.8426\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5620 - accuracy: 0.8061 - val_loss: 0.4419 - val_accuracy: 0.8442\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5610 - accuracy: 0.8039 - val_loss: 0.4379 - val_accuracy: 0.8444\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5557 - accuracy: 0.8066 - val_loss: 0.4366 - val_accuracy: 0.8438\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5475 - accuracy: 0.8091 - val_loss: 0.4350 - val_accuracy: 0.8460\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5455 - accuracy: 0.8100 - val_loss: 0.4313 - val_accuracy: 0.8450\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5454 - accuracy: 0.8087 - val_loss: 0.4306 - val_accuracy: 0.8463\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5403 - accuracy: 0.8096 - val_loss: 0.4301 - val_accuracy: 0.8461\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5389 - accuracy: 0.8130 - val_loss: 0.4291 - val_accuracy: 0.8475\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5371 - accuracy: 0.8117 - val_loss: 0.4273 - val_accuracy: 0.8498\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5336 - accuracy: 0.8144 - val_loss: 0.4234 - val_accuracy: 0.8506\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5326 - accuracy: 0.8166 - val_loss: 0.4223 - val_accuracy: 0.8502\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5273 - accuracy: 0.8171 - val_loss: 0.4200 - val_accuracy: 0.8521\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5252 - accuracy: 0.8162 - val_loss: 0.4200 - val_accuracy: 0.8506\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5211 - accuracy: 0.8187 - val_loss: 0.4177 - val_accuracy: 0.8508\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5143 - accuracy: 0.8216 - val_loss: 0.4163 - val_accuracy: 0.8522\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5148 - accuracy: 0.8196 - val_loss: 0.4125 - val_accuracy: 0.8530\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5119 - accuracy: 0.8208 - val_loss: 0.4129 - val_accuracy: 0.8520\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5141 - accuracy: 0.8210 - val_loss: 0.4105 - val_accuracy: 0.8546\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5068 - accuracy: 0.8257 - val_loss: 0.4113 - val_accuracy: 0.8533\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5071 - accuracy: 0.8230 - val_loss: 0.4097 - val_accuracy: 0.8537\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5088 - accuracy: 0.8227 - val_loss: 0.4080 - val_accuracy: 0.8541\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5004 - accuracy: 0.8251 - val_loss: 0.4074 - val_accuracy: 0.8533\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5003 - accuracy: 0.8236 - val_loss: 0.4037 - val_accuracy: 0.8547\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5005 - accuracy: 0.8267 - val_loss: 0.4043 - val_accuracy: 0.8567\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4968 - accuracy: 0.8264 - val_loss: 0.4029 - val_accuracy: 0.8571\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4949 - accuracy: 0.8284 - val_loss: 0.3998 - val_accuracy: 0.8574\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4921 - accuracy: 0.8290 - val_loss: 0.3997 - val_accuracy: 0.8587\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4884 - accuracy: 0.8303 - val_loss: 0.3995 - val_accuracy: 0.8594\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4879 - accuracy: 0.8298 - val_loss: 0.3970 - val_accuracy: 0.8593\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4210 - accuracy: 0.8480\n",
      "0.8479999899864197\n",
      "Accuracy: 84.80%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.2, with BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7245 - accuracy: 0.7479 - val_loss: 0.5080 - val_accuracy: 0.8260\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5077 - accuracy: 0.8201 - val_loss: 0.4144 - val_accuracy: 0.8537\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4550 - accuracy: 0.8367 - val_loss: 0.3863 - val_accuracy: 0.8639\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.4227 - accuracy: 0.8490 - val_loss: 0.3698 - val_accuracy: 0.8681\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4017 - accuracy: 0.8554 - val_loss: 0.3604 - val_accuracy: 0.8702\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3839 - accuracy: 0.8629 - val_loss: 0.3506 - val_accuracy: 0.8731\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3695 - accuracy: 0.8669 - val_loss: 0.3431 - val_accuracy: 0.8769\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3557 - accuracy: 0.8700 - val_loss: 0.3501 - val_accuracy: 0.8747\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3455 - accuracy: 0.8741 - val_loss: 0.3340 - val_accuracy: 0.8806\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3361 - accuracy: 0.8784 - val_loss: 0.3294 - val_accuracy: 0.8803\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3305 - accuracy: 0.8784 - val_loss: 0.3289 - val_accuracy: 0.8806\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3196 - accuracy: 0.8832 - val_loss: 0.3203 - val_accuracy: 0.8863\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3114 - accuracy: 0.8856 - val_loss: 0.3221 - val_accuracy: 0.8845\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3087 - accuracy: 0.8881 - val_loss: 0.3225 - val_accuracy: 0.8844\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.2985 - accuracy: 0.8890 - val_loss: 0.3115 - val_accuracy: 0.8863\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2948 - accuracy: 0.8909 - val_loss: 0.3190 - val_accuracy: 0.8855\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2877 - accuracy: 0.8946 - val_loss: 0.3111 - val_accuracy: 0.8863\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2825 - accuracy: 0.8948 - val_loss: 0.3091 - val_accuracy: 0.8895\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2790 - accuracy: 0.8991 - val_loss: 0.3080 - val_accuracy: 0.8883\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2725 - accuracy: 0.8996 - val_loss: 0.3072 - val_accuracy: 0.8878\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2646 - accuracy: 0.9015 - val_loss: 0.3072 - val_accuracy: 0.8906\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2628 - accuracy: 0.9035 - val_loss: 0.3197 - val_accuracy: 0.8845\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2591 - accuracy: 0.9046 - val_loss: 0.3047 - val_accuracy: 0.8917\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2533 - accuracy: 0.9057 - val_loss: 0.3062 - val_accuracy: 0.8892\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2498 - accuracy: 0.9071 - val_loss: 0.3046 - val_accuracy: 0.8908\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2448 - accuracy: 0.9086 - val_loss: 0.3068 - val_accuracy: 0.8905\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2421 - accuracy: 0.9114 - val_loss: 0.3064 - val_accuracy: 0.8905\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2356 - accuracy: 0.9136 - val_loss: 0.3126 - val_accuracy: 0.8870\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.2326 - accuracy: 0.9134 - val_loss: 0.3012 - val_accuracy: 0.8921\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2297 - accuracy: 0.9161 - val_loss: 0.3049 - val_accuracy: 0.8912\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.2253 - accuracy: 0.9172 - val_loss: 0.3049 - val_accuracy: 0.8923\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.2216 - accuracy: 0.9181 - val_loss: 0.3045 - val_accuracy: 0.8917\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2244 - accuracy: 0.9168 - val_loss: 0.2972 - val_accuracy: 0.8947\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2194 - accuracy: 0.9187 - val_loss: 0.3033 - val_accuracy: 0.8931\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2125 - accuracy: 0.9206 - val_loss: 0.3006 - val_accuracy: 0.8903\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.2107 - accuracy: 0.9212 - val_loss: 0.3020 - val_accuracy: 0.8932\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2088 - accuracy: 0.9222 - val_loss: 0.3034 - val_accuracy: 0.8921\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2082 - accuracy: 0.9227 - val_loss: 0.3076 - val_accuracy: 0.8907\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.2027 - accuracy: 0.9256 - val_loss: 0.3075 - val_accuracy: 0.8917\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2011 - accuracy: 0.9256 - val_loss: 0.3083 - val_accuracy: 0.8917\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1984 - accuracy: 0.9272 - val_loss: 0.3029 - val_accuracy: 0.8915\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1936 - accuracy: 0.9280 - val_loss: 0.3065 - val_accuracy: 0.8932\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1912 - accuracy: 0.9294 - val_loss: 0.3039 - val_accuracy: 0.8942\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1877 - accuracy: 0.9314 - val_loss: 0.3123 - val_accuracy: 0.8905\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1864 - accuracy: 0.9300 - val_loss: 0.3144 - val_accuracy: 0.8915\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1853 - accuracy: 0.9306 - val_loss: 0.3089 - val_accuracy: 0.8929\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.1804 - accuracy: 0.9334 - val_loss: 0.3109 - val_accuracy: 0.8915\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.1795 - accuracy: 0.9335 - val_loss: 0.3167 - val_accuracy: 0.8922\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1759 - accuracy: 0.9346 - val_loss: 0.3120 - val_accuracy: 0.8920\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1731 - accuracy: 0.9363 - val_loss: 0.3162 - val_accuracy: 0.8903\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1729 - accuracy: 0.9364 - val_loss: 0.3100 - val_accuracy: 0.8957\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1685 - accuracy: 0.9379 - val_loss: 0.3068 - val_accuracy: 0.8942\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1670 - accuracy: 0.9382 - val_loss: 0.3222 - val_accuracy: 0.8928\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.1659 - accuracy: 0.9380 - val_loss: 0.3068 - val_accuracy: 0.8956\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.1627 - accuracy: 0.9396 - val_loss: 0.3217 - val_accuracy: 0.8928\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1628 - accuracy: 0.9398 - val_loss: 0.3195 - val_accuracy: 0.8937\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1577 - accuracy: 0.9422 - val_loss: 0.3176 - val_accuracy: 0.8930\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1592 - accuracy: 0.9403 - val_loss: 0.3169 - val_accuracy: 0.8951\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1539 - accuracy: 0.9430 - val_loss: 0.3237 - val_accuracy: 0.8938\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.1570 - accuracy: 0.9432 - val_loss: 0.3250 - val_accuracy: 0.8935\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8855\n",
      "0.8855000138282776\n",
      "Accuracy: 88.55%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.5, with BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 1.0639 - accuracy: 0.6358 - val_loss: 0.6040 - val_accuracy: 0.7910\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6905 - accuracy: 0.7562 - val_loss: 0.4847 - val_accuracy: 0.8267\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.6121 - accuracy: 0.7832 - val_loss: 0.4523 - val_accuracy: 0.8390\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.5653 - accuracy: 0.7994 - val_loss: 0.4338 - val_accuracy: 0.8446\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5367 - accuracy: 0.8099 - val_loss: 0.4155 - val_accuracy: 0.8517\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5125 - accuracy: 0.8190 - val_loss: 0.4058 - val_accuracy: 0.8540\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4924 - accuracy: 0.8261 - val_loss: 0.4006 - val_accuracy: 0.8563\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4790 - accuracy: 0.8294 - val_loss: 0.3919 - val_accuracy: 0.8590\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4672 - accuracy: 0.8338 - val_loss: 0.3891 - val_accuracy: 0.8608\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4560 - accuracy: 0.8370 - val_loss: 0.3832 - val_accuracy: 0.8627\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.4488 - accuracy: 0.8385 - val_loss: 0.3724 - val_accuracy: 0.8650\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4379 - accuracy: 0.8440 - val_loss: 0.3683 - val_accuracy: 0.8654\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4268 - accuracy: 0.8449 - val_loss: 0.3661 - val_accuracy: 0.8681\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4244 - accuracy: 0.8478 - val_loss: 0.3693 - val_accuracy: 0.8669\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4166 - accuracy: 0.8494 - val_loss: 0.3599 - val_accuracy: 0.8702\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4126 - accuracy: 0.8503 - val_loss: 0.3645 - val_accuracy: 0.8711\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.4054 - accuracy: 0.8547 - val_loss: 0.3535 - val_accuracy: 0.8739\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.4016 - accuracy: 0.8568 - val_loss: 0.3492 - val_accuracy: 0.8742\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3984 - accuracy: 0.8584 - val_loss: 0.3487 - val_accuracy: 0.8736\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3910 - accuracy: 0.8589 - val_loss: 0.3474 - val_accuracy: 0.8756\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3828 - accuracy: 0.8624 - val_loss: 0.3455 - val_accuracy: 0.8767\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3834 - accuracy: 0.8613 - val_loss: 0.3445 - val_accuracy: 0.8777\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3790 - accuracy: 0.8636 - val_loss: 0.3419 - val_accuracy: 0.8763\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.3721 - accuracy: 0.8650 - val_loss: 0.3365 - val_accuracy: 0.8789\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3709 - accuracy: 0.8666 - val_loss: 0.3386 - val_accuracy: 0.8783\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3675 - accuracy: 0.8659 - val_loss: 0.3316 - val_accuracy: 0.8801\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3625 - accuracy: 0.8701 - val_loss: 0.3341 - val_accuracy: 0.8802\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3568 - accuracy: 0.8723 - val_loss: 0.3322 - val_accuracy: 0.8821\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3579 - accuracy: 0.8703 - val_loss: 0.3301 - val_accuracy: 0.8813\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3559 - accuracy: 0.8723 - val_loss: 0.3337 - val_accuracy: 0.8801\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3522 - accuracy: 0.8740 - val_loss: 0.3307 - val_accuracy: 0.8790\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3519 - accuracy: 0.8736 - val_loss: 0.3296 - val_accuracy: 0.8816\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3443 - accuracy: 0.8754 - val_loss: 0.3257 - val_accuracy: 0.8841\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3452 - accuracy: 0.8745 - val_loss: 0.3275 - val_accuracy: 0.8791\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3395 - accuracy: 0.8756 - val_loss: 0.3266 - val_accuracy: 0.8828\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3387 - accuracy: 0.8771 - val_loss: 0.3242 - val_accuracy: 0.8838\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3387 - accuracy: 0.8782 - val_loss: 0.3228 - val_accuracy: 0.8834\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3363 - accuracy: 0.8789 - val_loss: 0.3193 - val_accuracy: 0.8857\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3297 - accuracy: 0.8803 - val_loss: 0.3204 - val_accuracy: 0.8853\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3297 - accuracy: 0.8783 - val_loss: 0.3219 - val_accuracy: 0.8825\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3277 - accuracy: 0.8817 - val_loss: 0.3175 - val_accuracy: 0.8867\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3234 - accuracy: 0.8826 - val_loss: 0.3137 - val_accuracy: 0.8849\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3214 - accuracy: 0.8824 - val_loss: 0.3174 - val_accuracy: 0.8852\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3198 - accuracy: 0.8830 - val_loss: 0.3180 - val_accuracy: 0.8867\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3179 - accuracy: 0.8842 - val_loss: 0.3228 - val_accuracy: 0.8847\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3169 - accuracy: 0.8845 - val_loss: 0.3153 - val_accuracy: 0.8875\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3135 - accuracy: 0.8853 - val_loss: 0.3160 - val_accuracy: 0.8861\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.3091 - accuracy: 0.8860 - val_loss: 0.3162 - val_accuracy: 0.8876\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3087 - accuracy: 0.8865 - val_loss: 0.3135 - val_accuracy: 0.8886\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3101 - accuracy: 0.8864 - val_loss: 0.3145 - val_accuracy: 0.8873\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3076 - accuracy: 0.8863 - val_loss: 0.3127 - val_accuracy: 0.8876\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3049 - accuracy: 0.8882 - val_loss: 0.3112 - val_accuracy: 0.8892\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3019 - accuracy: 0.8904 - val_loss: 0.3172 - val_accuracy: 0.8852\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2992 - accuracy: 0.8908 - val_loss: 0.3107 - val_accuracy: 0.8885\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3009 - accuracy: 0.8905 - val_loss: 0.3134 - val_accuracy: 0.8867\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2973 - accuracy: 0.8917 - val_loss: 0.3090 - val_accuracy: 0.8878\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2997 - accuracy: 0.8903 - val_loss: 0.3085 - val_accuracy: 0.8877\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2954 - accuracy: 0.8912 - val_loss: 0.3054 - val_accuracy: 0.8895\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2923 - accuracy: 0.8907 - val_loss: 0.3060 - val_accuracy: 0.8907\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.2928 - accuracy: 0.8924 - val_loss: 0.3086 - val_accuracy: 0.8886\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8816\n",
      "0.881600022315979\n",
      "Accuracy: 88.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model (Drop rate : 0.8, with BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 14ms/step - loss: 2.0191 - accuracy: 0.3192 - val_loss: 1.0255 - val_accuracy: 0.6790\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 1.3027 - accuracy: 0.5304 - val_loss: 0.7753 - val_accuracy: 0.7373\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 1.0819 - accuracy: 0.6018 - val_loss: 0.7039 - val_accuracy: 0.7505\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.9767 - accuracy: 0.6427 - val_loss: 0.6691 - val_accuracy: 0.7624\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.8964 - accuracy: 0.6703 - val_loss: 0.6348 - val_accuracy: 0.7768\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.8482 - accuracy: 0.6897 - val_loss: 0.6112 - val_accuracy: 0.7829\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.8080 - accuracy: 0.7076 - val_loss: 0.5990 - val_accuracy: 0.7896\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.7827 - accuracy: 0.7150 - val_loss: 0.5759 - val_accuracy: 0.7980\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7638 - accuracy: 0.7235 - val_loss: 0.5636 - val_accuracy: 0.8043\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.7313 - accuracy: 0.7351 - val_loss: 0.5526 - val_accuracy: 0.8102\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.7192 - accuracy: 0.7421 - val_loss: 0.5423 - val_accuracy: 0.8134\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.7021 - accuracy: 0.7487 - val_loss: 0.5252 - val_accuracy: 0.8181\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.6894 - accuracy: 0.7554 - val_loss: 0.5181 - val_accuracy: 0.8221\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6815 - accuracy: 0.7587 - val_loss: 0.5207 - val_accuracy: 0.8201\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.6691 - accuracy: 0.7607 - val_loss: 0.5085 - val_accuracy: 0.8253\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6635 - accuracy: 0.7662 - val_loss: 0.5101 - val_accuracy: 0.8235\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.6472 - accuracy: 0.7703 - val_loss: 0.4934 - val_accuracy: 0.8301\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6447 - accuracy: 0.7700 - val_loss: 0.4903 - val_accuracy: 0.8309\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6341 - accuracy: 0.7760 - val_loss: 0.4886 - val_accuracy: 0.8325\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6230 - accuracy: 0.7799 - val_loss: 0.4795 - val_accuracy: 0.8329\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.6131 - accuracy: 0.7841 - val_loss: 0.4799 - val_accuracy: 0.8330\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6078 - accuracy: 0.7869 - val_loss: 0.4711 - val_accuracy: 0.8372\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.6102 - accuracy: 0.7858 - val_loss: 0.4692 - val_accuracy: 0.8392\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.6015 - accuracy: 0.7882 - val_loss: 0.4713 - val_accuracy: 0.8357\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5959 - accuracy: 0.7890 - val_loss: 0.4571 - val_accuracy: 0.8412\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5918 - accuracy: 0.7913 - val_loss: 0.4604 - val_accuracy: 0.8367\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5830 - accuracy: 0.7961 - val_loss: 0.4516 - val_accuracy: 0.8428\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5782 - accuracy: 0.7972 - val_loss: 0.4507 - val_accuracy: 0.8418\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.5809 - accuracy: 0.7960 - val_loss: 0.4519 - val_accuracy: 0.8428\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5718 - accuracy: 0.7971 - val_loss: 0.4476 - val_accuracy: 0.8444\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5675 - accuracy: 0.8021 - val_loss: 0.4462 - val_accuracy: 0.8454\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 7s 18ms/step - loss: 0.5638 - accuracy: 0.8024 - val_loss: 0.4443 - val_accuracy: 0.8441\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5605 - accuracy: 0.8049 - val_loss: 0.4393 - val_accuracy: 0.8488\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5596 - accuracy: 0.8026 - val_loss: 0.4386 - val_accuracy: 0.8472\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5515 - accuracy: 0.8058 - val_loss: 0.4362 - val_accuracy: 0.8472\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5498 - accuracy: 0.8076 - val_loss: 0.4340 - val_accuracy: 0.8468\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5476 - accuracy: 0.8092 - val_loss: 0.4308 - val_accuracy: 0.8467\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.5430 - accuracy: 0.8084 - val_loss: 0.4315 - val_accuracy: 0.8458\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5432 - accuracy: 0.8103 - val_loss: 0.4317 - val_accuracy: 0.8468\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5413 - accuracy: 0.8125 - val_loss: 0.4307 - val_accuracy: 0.8480\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5379 - accuracy: 0.8124 - val_loss: 0.4253 - val_accuracy: 0.8521\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5345 - accuracy: 0.8139 - val_loss: 0.4220 - val_accuracy: 0.8536\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5323 - accuracy: 0.8145 - val_loss: 0.4171 - val_accuracy: 0.8524\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5271 - accuracy: 0.8152 - val_loss: 0.4192 - val_accuracy: 0.8538\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5226 - accuracy: 0.8180 - val_loss: 0.4174 - val_accuracy: 0.8526\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5226 - accuracy: 0.8167 - val_loss: 0.4205 - val_accuracy: 0.8547\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5205 - accuracy: 0.8180 - val_loss: 0.4177 - val_accuracy: 0.8536\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5147 - accuracy: 0.8208 - val_loss: 0.4123 - val_accuracy: 0.8547\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5176 - accuracy: 0.8200 - val_loss: 0.4162 - val_accuracy: 0.8540\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5132 - accuracy: 0.8193 - val_loss: 0.4166 - val_accuracy: 0.8532\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5133 - accuracy: 0.8208 - val_loss: 0.4113 - val_accuracy: 0.8547\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.5134 - accuracy: 0.8192 - val_loss: 0.4090 - val_accuracy: 0.8549\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5062 - accuracy: 0.8225 - val_loss: 0.4135 - val_accuracy: 0.8509\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.5067 - accuracy: 0.8211 - val_loss: 0.4094 - val_accuracy: 0.8546\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 8s 20ms/step - loss: 0.5078 - accuracy: 0.8237 - val_loss: 0.4054 - val_accuracy: 0.8563\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 6s 15ms/step - loss: 0.5053 - accuracy: 0.8232 - val_loss: 0.4078 - val_accuracy: 0.8583\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.5057 - accuracy: 0.8248 - val_loss: 0.4043 - val_accuracy: 0.8572\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.5008 - accuracy: 0.8242 - val_loss: 0.4008 - val_accuracy: 0.8586\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.4939 - accuracy: 0.8283 - val_loss: 0.4037 - val_accuracy: 0.8577\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.5005 - accuracy: 0.8251 - val_loss: 0.4022 - val_accuracy: 0.8597\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4243 - accuracy: 0.8516\n",
      "0.8515999913215637\n",
      "Accuracy: 85.16%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics[1])\n",
    "print(f'Accuracy: {metrics[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 분석\n",
    "최종 결과는 다음과 같다.\n",
    "(BN은 Batch Normalization을 나타냄)\n",
    "\n",
    "- Drop rate = 0.2, no BN : 87.61%\n",
    "- Drop rate = 0.5, no BN : 86.98%\n",
    "- Drop rate = 0.8, no BN : 84.80%\n",
    "- Drop rate = 0.2, with BN : 88.55%\n",
    "- Drop rate = 0.5, with BN : 88.16%\n",
    "- Drop rate = 0.8, with BN : 85.16%\n",
    "\n",
    "Drop rate는 해당 확률로 뉴런을 제거를 하겠다는 것을 의미한다.\n",
    "과적합 방지를 위해 이러한 기법을 사용한다.\n",
    "전체적으로 결과를 봤을 때 BN을 적용한 결과에서나 적용하지 않은 결과에서나\n",
    "Drop rate가 높아질수록 정확도가 떨어지는 것을 확인할 수 있다.\n",
    "이는 너무 높은 확률로 drop을 하게 되면 과소 학습된 결과가 나올 수 있기 때문이다.\n",
    "또한 같은 drop rate에 대해서는\n",
    "BN(Batch Normalization)을 사용한 결과가 전체적으로 더 정확도가 높은 것을 확인할 수 있다.\n",
    "이는 BN을 사용하게 되면\n",
    "layer 각 층마다 활성화 값을 normalize하기 때문에\n",
    "초기값 선택의 영향을 적게 받게 되기 때문이다.\n",
    "또한 기울기 손실(Gradient Vanishing)문제도 해결이 되기 때문에\n",
    "정확도가 더 높아진다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
